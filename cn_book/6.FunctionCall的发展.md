# FunctionCall的发展

> 2025 年 3 月至 9 月的进展与展望


## 一、引言

大型语言模型 (Large Language Models, LLMs) 作为人工智能领域的核心技术，已经在自然语言理解、生成和推理等方面展现出惊人的能力。然而，这些模型在处理需要实时信息获取、复杂计算或与外部系统交互的任务时仍存在局限性。FunctionCall 技术作为一种关键的扩展能力，允许 LLMs 与外部工具、API 和服务进行交互，极大地扩展了模型的应用范围和功能边界。通过 FunctionCall，LLMs 能够执行计算、查询数据库、调用第三方服务等操作，从而解决那些原本超出其固有能力的复杂任务。

随着 2023 年 Toolformer 的提出，FunctionCall 技术进入了快速发展阶段。到 2025 年，FunctionCall 已经成为学术界和工业界研究的热点，各种新方法和应用场景不断涌现。FunctionCall 技术的核心优势在于它允许 LLMs 保留其语言理解和生成能力的同时，能够利用外部工具的专业性和效率，实现 "1+1>2" 的效果。

本文旨在对 2025 年 3 月至 9 月期间 FunctionCall 技术的最新研究进展进行全面综述，涵盖通用大模型和垂直行业应用两大方向。通过对最新文献的系统梳理，本文将分析 FunctionCall 技术的关键创新点、性能表现以及未来发展趋势，为相关研究和应用提供参考。

## 二、FunctionCall 技术基础与研究进展

### 2.1 FunctionCall 技术的基本概念

FunctionCall 技术允许 LLMs 在处理用户查询时，能够根据需要调用外部函数或工具，并利用其返回结果继续处理后续任务。这一过程通常包括三个关键步骤：确定是否需要调用工具、选择合适的工具以及正确解释工具的返回结果。FunctionCall 技术的核心思想是将 LLMs 的自然语言理解能力与外部工具的特定功能相结合，从而扩展模型的应用范围。

FunctionCall 技术的实现方式主要有两种：一种是通过专门的 API 接口实现，如 OpenAI 的 FunctionCall API；另一种是通过更灵活的代理 (Agent) 架构实现，如 LangChain 框架。前者通常需要模型在训练阶段就已经 "学习" 了如何使用这些工具，而后者则允许在部署后动态添加新工具。

### 2.2 2025 年 FunctionCall 技术的主要研究方向

2025 年的 FunctionCall 研究主要集中在以下几个方向：

**FunctionCall 优化与并行处理**：研究如何提高 FunctionCall 的效率和可靠性，特别是在处理复杂多步骤任务时的性能优化。这方面的研究包括如何优化函数调用的顺序、如何并行执行多个函数调用以及如何处理函数之间的依赖关系。

**FunctionCall 与推理能力结合**：探索如何通过 FunctionCall 增强 LLMs 的推理能力，特别是在需要多步推理和外部知识的任务中。这方面的研究包括如何利用函数调用进行数学计算、逻辑推理和复杂问题求解。

**FunctionCall 与多模态融合**：研究如何将 FunctionCall 与图像、音频等多模态输入输出结合，扩展 LLMs 的应用场景。这方面的研究包括如何通过函数调用处理图像识别、语音合成等任务。

**FunctionCall 的可靠性与安全性**：探讨如何提高 FunctionCall 的可靠性，减少错误调用和错误解释，并确保在敏感应用中的安全性。这方面的研究包括如何设计有效的验证机制、如何处理异常情况以及如何保护用户隐私。

**FunctionCall 的垂直行业应用**：研究如何将 FunctionCall 技术应用于金融、医疗、教育等特定行业，解决行业内的实际问题。这方面的研究包括如何针对特定行业需求设计专用工具、如何优化行业特定任务的 FunctionCall 流程以及如何评估行业应用的效果。

## 三、通用大模型中的 FunctionCall 技术

### 3.1 FunctionCall 机制的改进与优化

2025 年，研究者们在 FunctionCall 机制的设计和实现方面提出了多项创新。Wang 和 Xu 提出了一种将知识回忆机制抽象为功能结构的方法，将模型的隐藏激活空间视为一个函数执行过程，其中特定的激活向量对应于功能组件（输入参数、函数体和返回值）。这种方法有助于更好地理解 LLMs 内部的知识表示和调用机制，并为改进 FunctionCall 提供了理论基础。

Liu 等人提出了 LLMOrch 框架，该框架通过引入数据和控制关系的新考虑，将调度和执行过程分离，实现了函数调用的并行编排。LLMOrch 将函数调用的编排分解为三个步骤：查询翻译、关系发现和调度执行。实验表明，LLMOrch 在协调 I/O 密集型和计算密集型函数方面表现出色，在多个基准测试中实现了显著的性能提升。

Song 等人提出了 CallNavi，这是一个专门用于评估 LLMs 在 API 函数选择、参数生成和嵌套 API 执行方面能力的基准数据集。CallNavi 引入了一种混合方法，将通用大型语言模型用于 API 选择，与微调模型和提示工程相结合用于参数生成，显著提高了聊天机器人系统中的 API 执行效率。

### 3.2 FunctionCall 的并行处理与优化

FunctionCall 的并行处理是 2025 年研究的一个重点方向。Gim 等人提出了 AsyncLM，这是一个用于异步 LLM 函数调用的系统，通过引入中断机制，使 LLMs 能够在函数调用返回时异步接收通知，从而提高了 LLM 的操作效率。AsyncLM 允许 LLMs 同时生成和执行函数调用，在伯克利函数调用排行榜 (BFCL) 上的基准测试中，AsyncLM 将端到端任务完成延迟降低了 1.6×-5.4×。

Sinha 等人提出了 Financial Agent，这是一种知识接地方法，使 LLMs 能够使用实时文本和表格数据处理金融查询。该方法引入了一个包含超过 50,000 个金融查询的金融上下文数据集，并训练了一个定制的 70 亿参数 LLM——FinBloom 7B，通过减少延迟和消除用户手动提供准确数据的需要，显著增强了 LLMs 处理动态金融任务的能力。

Paramanayakam 等人提出了 Less-is-More，这是一种新颖的无微调函数调用方案，用于动态工具选择。该方法基于选择性减少 LLMs 可用工具数量可以显著提高其函数调用性能、执行时间和能效的关键见解。实验结果表明，Less-is-More 在边缘设备上实现了高达 70% 的执行时间减少和高达 40% 的功耗降低。

### 3.3 FunctionCall 与知识增强

FunctionCall 与知识增强的结合是 2025 年的另一个研究热点。Schick 等人提出的 Toolformer 展示了 LLMs 可以通过简单的 API 自学使用外部工具，实现两者的优势结合。Toolformer 通过自监督方式训练模型决定调用哪些 API、何时调用它们、传递什么参数以及如何最好地将结果整合到未来的令牌预测中。

Erdogan 等人提出了 TinyAgent，这是一个端到端框架，用于训练和部署能够在边缘设备上进行函数调用的特定任务小型语言模型代理。TinyAgent 展示了如何通过 LLMCompiler 框架为开源模型启用准确的函数调用，并通过系统地策划高质量的函数调用数据集，对两个小型语言模型 TinyAgent-1.1B 和 7B 进行微调，实现了在边缘设备上的高效推理。

Li 等人提出了 FNCTOD，这是一种通过函数调用解决对话状态跟踪问题的新方法。该方法提高了零样本对话状态跟踪能力，允许在无需大量数据收集或模型调整的情况下适应不同领域。实验结果表明，FNCTOD 在多个基准测试中取得了优异的性能，使各种 7B 或 13B 参数模型能够超越 ChatGPT 之前达到的 SOTA，并将 ChatGPT 的性能提高了 5.6% 的平均联合目标准确率 (JGA)。

## 四、垂直行业中的 FunctionCall 应用

### 4.1 金融领域的 FunctionCall 应用

金融领域是 FunctionCall 技术应用的重要场景。Zhao 等人在《Revolutionizing Finance with LLMs》一文中全面概述了 LLMs 在金融领域的应用，包括函数调用在金融决策中的应用。他们指出，FunctionCall 技术使 LLMs 能够访问实时金融数据、执行复杂计算和生成金融分析，从而支持更明智的投资决策。

Sinha 等人开发的 FinBloom 是一个基于知识接地的大型语言模型，专门用于处理实时金融数据。FinBloom 通过结合 1400 万篇金融新闻文章和 1200 万份美国证券交易委员会 (SEC) 文件进行训练，并通过金融上下文数据集进行微调，生成相关的金融上下文，实现高效的实时数据检索，以回答用户查询。这一方法显著增强了 LLMs 处理动态金融任务的能力，使实时金融决策、算法交易和其他相关任务变得更加高效。

Bhan 等人提出了 ThorV2，这是一种新型架构，显著增强了 LLMs 的函数调用能力。他们开发了一个专注于 HubSpot CRM 操作的综合基准，用于评估 ThorV2 与 OpenAI 和 Anthropic 的领先模型。结果表明，ThorV2 在准确性、可靠性、延迟和成本效率方面均优于现有模型，在单 API 和多 API 调用任务中表现出色。

### 4.2 医疗与生物科学中的 FunctionCall 应用

在医疗和生物科学领域，FunctionCall 技术也展现出巨大潜力。Li 等人提出了 DrugPilot，这是一个基于 LLM 的参数化推理代理，用于药物发现。DrugPilot 通过其参数推理架构解决了传统端到端 LLM 预测方法的关键限制，支持药物发现管道的主要阶段，促进多阶段研究任务的自动化规划和执行。

Ma 等人提出了 ProtTeX，这是一个将蛋白质序列、结构和文本信息标记化为统一离散空间的框架。ProtTeX 使通用 LLMs 能够通过顺序文本输入感知和处理蛋白质结构，利用结构信息作为中间推理组件，并通过顺序文本输出生成或操作结构。实验表明，ProtTeX 在蛋白质功能预测方面取得了显著改进，准确性比最先进的领域专家模型提高了两倍。

Zagar 等人提出了一种将 LLM 执行环境从集中式云提供商转移到分散式动态雾计算架构的方法。通过在更可信的环境（如用户的边缘设备或本地网络内的雾层）中执行开放权重 LLMs，他们旨在减轻与基于云的 LLMs 相关的隐私、信任和财务挑战。他们还提出了 SpeziLLM，这是一个开源框架，旨在促进不同 LLM 执行层的快速无缝利用，并降低 LLM 集成在数字健康应用中的障碍。

### 4.3 教育与研究中的 FunctionCall 应用

在教育和研究领域，FunctionCall 技术为知识获取和分析提供了新的可能性。Hu 等人提出了 LEAP，这是一个由 LLM 驱动的端到端自动库，用于处理社会科学查询。LEAP 过滤模糊查询以确保答案的确定性，并从内部支持的和用户定义的 ML 函数中进行选择，将非结构化数据扩展到具有必要注释的结构化表。LEAP 进一步生成并执行代码以响应这些自然语言查询，在 QUIET-ML 数据集上实现了 100% 的 pass@3 和 92% 的 pass@1。

Zhao 等人研究了 AIGC 工具在 "现代教育技术" 课程中的应用。他们概述了 AIGC (人工智能生成内容) 的国内外发展现状，分析了 AIGC 在教育领域的应用现状，在技术层面解析了 AIGC 工具的分类及应用，提出了 "现代教育技术" 课程中 AIGC 工具的选择标准，并设计了基于开源 AIGC 模型的多模态平台方案。

### 4.4 软件开发与工程中的 FunctionCall 应用

在软件开发和工程领域，FunctionCall 技术已经成为提高开发效率的重要工具。Shorten 等人研究了如何使用 FunctionCall 进行数据库查询，提出并广泛测试了一种数据库查询的工具定义，该定义统一了使用搜索查询、过滤器或两者组合来访问数据，以及使用聚合和分组操作符转换结果。他们的研究表明，FunctionCall 可以有效地将 LLMs 与数据库查询连接起来，实现更高效的数据检索和分析。

Kang 等人提出了 LEAP，这是一个回答自然语言社会科学查询的端到端库。LEAP 通过选择内部支持的和用户定义的 ML 函数来扩展非结构化数据到结构化表，进一步生成并执行代码以响应这些自然语言查询。LEAP 的设计特别关注社会科学研究中的挑战，如需要选择和应用 ML 模型，以及处理模糊查询的能力。

Wu 等人提出了 ToolACE，这是一个自动代理管道，用于生成准确、复杂和多样化的工具学习数据。ToolACE 利用一种新颖的自我进化合成过程来策划包含 26,507 个多样化 API 的综合 API 池，并通过多个代理之间的相互作用生成对话，由形式化思维过程引导。为确保数据准确性，他们实施了一个结合基于规则和基于模型检查的双层验证系统。实验表明，在他们的合成数据上训练的模型，即使只有 8B 参数，也能在伯克利函数调用排行榜上达到最先进的性能，与最新的 GPT-4 模型相媲美。

## 五、FunctionCall 技术的性能评估

### 5.1 评估指标与方法

在 FunctionCall 技术的评估方面，研究者们提出了多种指标和方法。Song 等人在 CallNavi 研究中提出了多种评估指标，包括 API 参数 AST 匹配、LLM-as-Judge 评估和稳定性评分。API 参数 AST 匹配利用抽象语法树 (AST) 评估来评估模型生成准确 API 调用 JSON 输出的能力，包括语法有效性、结构准确性和 AST 精确匹配。LLM-as-Judge 评估使用 GPT-4o 语言模型来评估生成的 JSON 输出是否准确对应于真实情况。稳定性评分则评估了模型在多次运行中 API 输出的一致性。

CallNavi 还引入了选举稳定性评分 (Election Stability Score)，该评分反映了模型输出的一致性。评分范围从 0 到 1，1 表示完美稳定性，0 表示没有稳定性。这个指标特别有用，因为它揭示了传统指标可能忽略的差异。例如，在平局情况下（如 2 vs 2 vs 1），稳定性评分为 0；在高多数情况下（如 4 vs 1），稳定性评分为 0.75。

Liu 等人在评估 LLMOrch 时使用了多种指标，包括准确性、延迟和令牌成本。准确性评估模型是否能够正确解决用户的问题；延迟测量从用户查询到获得响应的端到端运行时间；令牌成本则衡量在处理用户查询过程中消耗的输入和输出令牌总数。这些指标有助于全面评估 FunctionCall 技术在不同场景下的性能。

### 5.2 不同模型与技术的性能比较

在不同模型和技术的性能比较方面，Song 等人的研究显示，在大型通用开源 LLM 中，LLAMA3.1（70B）在简单任务中的精确匹配得分为 0.945，但在较难的情况下表现显著下降（0.470）。OpenAI 的 GPT-4o 和 GPT-4o mini 在语法有效性（分别为 0.993 和 0.994）和整体 GPT 分数（0.913 和 0.908）方面始终优于其他模型。CommandR（35B）在中型 API 调用任务中表现相对较强（0.877），但在结构准确性（0.189）和 API 参数 AST 匹配（0.134）方面表现不佳。

Liu 等人的研究表明，LLMOrch 在多个基准测试中表现出色。在 KITTI \* 基准测试中，当分配 8 个处理器时，LLMOrch 的加速比达到 3.26 倍，而 LLMCompiler 仅达到 1.25 倍。在 "购买意向分析" 案例研究中，运行在三个处理器上的 LLMOrch 响应时间约为 77.10 秒，比 ReAct 快约 1.71 倍，比 OpenAI PFC 快约 1.54 倍，比 LLMCompiler 快约 1.48 倍。这些结果表明，LLMOrch 在处理复杂函数调用任务时具有显著的性能优势。

Bhan 等人的研究显示，ThorV2 在准确性、可靠性、延迟和成本效率方面均优于 OpenAI 和 Anthropic 的领先模型。特别是在多步骤任务中，ThorV2 比传统模型更加可靠且扩展性更好。这一研究结果表明，通过 FunctionCall 技术的改进，可以使用显著更小的 LLMs 实现比当今最佳性能模型更准确的函数调用。

Li 等人的研究表明，FNCTOD 方法在对话状态跟踪任务中取得了显著的性能提升。通过上下文提示，各种 7B 或 13B 参数模型能够超越 ChatGPT 之前达到的 SOTA，将 ChatGPT 的性能提高了 5.6% 的平均联合目标准确率 (JGA)。具体来说，GPT-3.5 和 GPT-4 的性能分别提升了 4.8% 和 14%。

### 5.3 垂直行业应用的性能表现

在垂直行业应用的性能表现方面，Sinha 等人开发的 FinBloom 在处理金融查询时表现出色。通过结合实时金融数据和 FunctionCall 技术，FinBloom 能够准确回答复杂的金融问题，显著减少了延迟并消除了用户手动提供准确数据的需要。这一方法在高速度数据流环境中特别有价值，能够支持实时金融决策和算法交易。

Li 等人开发的 DrugPilot 在药物发现任务中表现出了很高的准确性。在简单、多重和多轮任务中，DrugPilot 分别实现了 98.0%、93.5% 和 64.0% 的任务完成率。这一性能表明，FunctionCall 技术在复杂的科学研究领域具有巨大潜力，能够辅助科学家进行更高效的药物发现和设计。

Erdogan 等人开发的 TinyAgent 在边缘设备上实现了令人印象深刻的性能。他们的实验表明，TinyAgent 模型能够达到甚至超过更大模型（如 GPT-4-Turbo）的函数调用能力，同时完全部署在边缘设备上。这一成果对于资源受限的环境中的应用具有重要意义，使 FunctionCall 技术能够在更广泛的场景中得到应用。

Bhan 等人的研究表明，ThorV2 在 HubSpot CRM 操作的基准测试中表现出色，在准确性、可靠性、延迟和成本效率方面均优于现有模型。这一结果表明，FunctionCall 技术在企业级应用中具有显著的实用价值，能够提高工作效率和决策质量。

## 六、FunctionCall 技术的挑战与未来发展方向

### 6.1 当前技术的主要挑战

尽管 FunctionCall 技术在近年来取得了显著进展，但仍面临多项挑战。首先是**可靠性与稳定性挑战**。FunctionCall 技术在处理复杂、模糊或多步骤任务时，可靠性和稳定性仍然是主要问题。Song 等人的研究表明，许多模型在较难的任务中表现显著下降，如 LLAMA3.1（70B）在简单任务中的精确匹配得分为 0.945，但在较难的情况下下降到 0.470。

其次是**效率与延迟挑战**。随着 FunctionCall 复杂度的增加，特别是在需要调用多个工具或 API 的情况下，延迟可能会显著增加。虽然一些研究如 LLMOrch 和 AsyncLM 已经提出了并行处理和优化方法，但在资源受限的环境中，如边缘设备上，效率仍然是一个重要挑战。

第三是**工具选择与参数生成挑战**。在众多可用工具中选择合适的工具，并为每个工具生成正确的参数，是 FunctionCall 技术面临的主要挑战之一。许多模型在结构准确性和 API 参数 AST 匹配方面表现不佳，如 CommandR（35B）的结构准确性为 0.189，API 参数 AST 匹配为 0.134。

第四是**数据质量与多样性挑战**。高质量和多样化的训练数据对于 FunctionCall 技术的成功至关重要。然而，真实的函数调用数据收集和注释非常困难，而合成数据往往缺乏覆盖范围和准确性。Wu 等人提出的 ToolACE 试图通过自动代理管道生成高质量、多样化的工具学习数据来解决这一问题。

第五是**多模态融合挑战**。将 FunctionCall 与图像、音频等多模态输入输出结合仍然面临技术挑战。虽然 Ma 等人的 ProtTeX 在蛋白质结构理解方面取得了进展，但在更广泛的多模态场景中，FunctionCall 的应用仍然有限。

### 6.2 未来研究方向与发展趋势

基于当前的研究进展和挑战，FunctionCall 技术的未来发展可以从以下几个方向展开：

**更高效的 FunctionCall 编排与执行**。未来的研究可以进一步探索函数调用的并行处理、优化调度和执行机制，以提高效率和减少延迟。LLMOrch 和 AsyncLM 等框架已经为此提供了初步思路，但仍有很大的改进空间，特别是在处理复杂依赖关系和动态环境时。

**FunctionCall 与推理能力的深度融合**。未来的研究可以探索如何通过 FunctionCall 增强 LLMs 的推理能力，特别是在需要多步推理和外部知识的任务中。Wang 和 Xu 提出的功能结构抽象方法为此提供了理论基础，但需要进一步的实证研究和应用扩展。

**FunctionCall 的自监督学习与自适应能力**。未来的研究可以探索如何使 LLMs 能够通过自监督学习不断改进 FunctionCall 能力，减少对人工标注数据的依赖。Schick 等人提出的 Toolformer 展示了这一方向的潜力，但在更复杂的场景和更多样化的工具上的应用仍需探索。

**FunctionCall 的可靠性与安全性增强**。未来的研究可以关注如何提高 FunctionCall 的可靠性，减少错误调用和错误解释，并确保在敏感应用中的安全性。这包括设计有效的验证机制、处理异常情况的方法以及保护用户隐私的技术。

**FunctionCall 在特定领域的深度应用**。未来的研究可以进一步探索 FunctionCall 在金融、医疗、教育等特定领域的深度应用，开发更专业、更高效的领域特定工具和方法。Sinha 等人的 FinBloom 和 Li 等人的 DrugPilot 展示了这一方向的潜力，但需要更多领域的深入研究和应用验证。

### 6.3 工业界应用的建议与策略

对于工业界应用，我们提出以下建议和策略：

**根据应用场景选择合适的 FunctionCall 技术**。不同的应用场景对 FunctionCall 的要求不同，应根据具体需求选择合适的技术和工具。例如，对于实时性要求高的金融应用，可以考虑使用 FinBloom 等专门优化的模型；对于资源受限的边缘设备，可以考虑使用 TinyAgent 等轻量级解决方案。

**注重 FunctionCall 的工程实现与优化**。在工业界应用中，FunctionCall 的工程实现和优化至关重要。应关注函数调用的效率、可靠性和可维护性，设计适当的监控和日志系统，及时发现和解决问题。Bhan 等人的研究表明，优化后的 FunctionCall 架构（如 ThorV2）可以在准确性、可靠性、延迟和成本效率方面显著优于现有模型。

**结合 FunctionCall 与其他 AI 技术**。FunctionCall 不应孤立使用，而应与其他 AI 技术如计算机视觉、自然语言处理和知识图谱等结合，形成更强大的解决方案。例如，Ma 等人的 ProtTeX 将 FunctionCall 与蛋白质结构分析结合，实现了蛋白质功能预测的显著改进。

**重视数据质量和标注**。高质量的训练数据是 FunctionCall 技术成功的关键。工业界应用应重视数据收集、清洗和标注工作，必要时可以考虑使用自动数据生成技术如 ToolACE 来提高数据质量和多样性。

**关注 FunctionCall 的安全性和合规性**。在处理敏感数据和执行关键操作时，FunctionCall 的安全性和合规性至关重要。工业界应用应设计适当的安全机制，如访问控制、数据加密和审计日志，确保 FunctionCall 的安全可靠运行。

## 七、结论

本文对 2025 年 3 月至 9 月期间 FunctionCall 技术在大语言模型应用中的研究进展进行了全面综述。我们首先介绍了 FunctionCall 技术的基本概念和研究方向，然后详细讨论了通用大模型中的 FunctionCall 技术改进与优化，接着探讨了 FunctionCall 在金融、医疗、教育和软件开发等垂直行业中的应用，随后评估了 FunctionCall 技术的性能指标和不同模型的表现，最后分析了当前技术的挑战并提出了未来研究方向和工业界应用建议。

研究表明，FunctionCall 技术作为大语言模型与外部工具和服务交互的桥梁，已经在多个领域展现出巨大潜力。在通用大模型方面，研究者们提出了多种 FunctionCall 机制的改进与优化方法，如功能结构抽象、并行处理和知识增强等，显著提高了 FunctionCall 的效率和可靠性。在垂直行业应用方面，FunctionCall 技术在金融、医疗、教育和软件开发等领域的应用取得了初步成功，为解决行业特定问题提供了新思路和方法。

然而，FunctionCall 技术仍面临可靠性与稳定性、效率与延迟、工具选择与参数生成、数据质量与多样性以及多模态融合等挑战。未来的研究可以从更高效的 FunctionCall 编排与执行、FunctionCall 与推理能力的深度融合、FunctionCall 的自监督学习与自适应能力、FunctionCall 的可靠性与安全性增强以及 FunctionCall 在特定领域的深度应用等方向展开。

总的来说，FunctionCall 技术正处于快速发展阶段，随着研究的深入和应用的扩展，它将为大语言模型在更广泛领域的应用提供强大支持，推动人工智能技术的进一步发展和应用。

**参考资料 **

\[1] Functional Abstraction of Knowledge Recall in Large Language Models[ https://arxiv.org/pdf/2504.14496](https://arxiv.org/pdf/2504.14496)

\[2] Optimizing Small Language Models for In-Vehicle Function-Calling[ https://arxiv.org/pdf/2501.02342](https://arxiv.org/pdf/2501.02342)

\[3] CallNavi, A Challenge and Empirical Study on LLM Function Calling and Routing[ https://arxiv.org/pdf/2501.05255](https://arxiv.org/pdf/2501.05255)

\[4] The Breeze 2 Herd of Models: Traditional Chinese LLMs Based on Llama with Vision-Aware and Function-Calling Capabilities[ https://arxiv.org/pdf/2501.13921](https://arxiv.org/pdf/2501.13921)

\[5] efficient function orchestration for large language models[ https://arxiv.org/pdf/2504.14872](https://arxiv.org/pdf/2504.14872)

\[6] Toolformer: Language Models Can Teach Themselves to Use Tools[ https://arxiv.org/pdf/2302.04761](https://arxiv.org/pdf/2302.04761)

\[7] FUNCTION VECTORS IN LARGE LANGUAGE MODELS[ https://openreview.net/pdf?id=AwyxtyMwaG](https://openreview.net/pdf?id=AwyxtyMwaG)

\[8] Large Language Models as Zero-shot Dialogue State Tracker through Function Calling[ https://arxiv.org/pdf/2402.10466](https://arxiv.org/pdf/2402.10466)

\[9] ToolACE: Winning the Points of LLM Function Calling[ https://arxiv.org/pdf/2409.00920](https://arxiv.org/pdf/2409.00920)

\[10] Less is More: Optimizing Function Calling for LLM Execution on Edge Devices[ https://arxiv.org/pdf/2411.15399](https://arxiv.org/pdf/2411.15399)

\[11] ASYNCHRONOUS LLM FUNCTION CALLING[ https://arxiv.org/pdf/2412.07017](https://arxiv.org/pdf/2412.07017)

\[12] TinyAgent: Function Calling at the Edge[ https://arxiv.org/pdf/2409.00608](https://arxiv.org/pdf/2409.00608)

\[13] Benchmarking Floworks against OpenAI & Anthropic: A Novel Framework for Enhanced LLM Function Calling[ https://arxiv.org/pdf/2410.17950](https://arxiv.org/pdf/2410.17950)

\[14] An LLM-Tool Compiler for Fused Parallel Function Calling[ https://arxiv.org/pdf/2405.17438](https://arxiv.org/pdf/2405.17438)

\[15] LLMPC: Large Language Model Predictive Control[ https://arxiv.org/pdf/2501.02486](https://arxiv.org/pdf/2501.02486)

\[16] Improving Small-Scale Large Language Models Function Calling for Reasoning Tasks[ https://arxiv.org/pdf/2410.18890](https://arxiv.org/pdf/2410.18890)

\[17] Achieving Tool Calling Functionality in LLMs Using Only Prompt Engineering Without Fine-Tuning[ https://arxiv.org/pdf/2407.04997](https://arxiv.org/pdf/2407.04997)

\[18] ProtTeX: Structure-In-Context Reasoning and Editing of Proteins with Large Language Models[ https://arxiv.org/pdf/2503.08179](https://arxiv.org/pdf/2503.08179)

\[19] FinBloom: Knowledge Grounding Large Language Model with Real-time Financial Data[ https://arxiv.org/pdf/2502.18471](https://arxiv.org/pdf/2502.18471)

\[20] Revolutionizing Finance with LLMs: An Overview of Applications and Insights[ https://arxiv.org/pdf/2401.11641](https://arxiv.org/pdf/2401.11641)

\[21] BloombergGPT: A Large Language Model for Finance[ https://arxiv.org/pdf/2303.17564](https://arxiv.org/pdf/2303.17564)

\[22] From LLM Reasoning to Autonomous AI Agents: A Comprehensive Review[ https://arxiv.org/pdf/2504.19678](https://arxiv.org/pdf/2504.19678)

\[23] 研究使用GPT构建大语言模型智能母基金决策投资支持系统 BUILDING A LARGE LANGUAGE MODELING INTELLIGENT FUND OF FUNDS DECISION MAKING AND INVESTMENT SUPPORT SYSTEM USING GPT[ https://www.cqvip.com/doc/journal/3344098944](https://www.cqvip.com/doc/journal/3344098944)

\[24] Data-centric FinGPT: Democratizing Internet-scale Data for Financial Large Language Models[ https://arxiv.org/pdf/2307.10485](https://arxiv.org/pdf/2307.10485)

\[25] CustomizedFinGPT Search Agents Using Foundation Models[ https://arxiv.org/pdf/2410.15284](https://arxiv.org/pdf/2410.15284)

\[26] ToolACE: Winning the Points of LLM Function Calling[ https://arxiv.org/pdf/2409.00920](https://arxiv.org/pdf/2409.00920)

\[27] A Survey of Large Language Models in Finance (FinLLMs)[ https://arxiv.org/pdf/2402.02315](https://arxiv.org/pdf/2402.02315)

\[28] ChatGPT的运行模式、关键技术及未来图景 ChatGPT:Operation Mode,Key Technology and Future Prospects[ http://m.qikan.cqvip.com/Article/ArticleDetail?id=7110682730](http://m.qikan.cqvip.com/Article/ArticleDetail?id=7110682730)

\[29] NAACL2025 Tutorial: Adaptation of Large Language Models[ https://arxiv.org/pdf/2504.03931](https://arxiv.org/pdf/2504.03931)

\[30] Can Large Language Models Trade? Testing Financial Theories with LLM Agents in Market Simulations[ https://arxiv.org/pdf/2504.10789](https://arxiv.org/pdf/2504.10789)

\[31] DrugPilot: LLM-based Parameterized Reasoning Agent for Drug Discovery[ https://arxiv.org/pdf/2505.13940](https://arxiv.org/pdf/2505.13940)

\[32] AIGC工具在“现代教育技术”课程中的应用研究 Research on application of AIGC tool in modern educational technology course[ https://m.zhangqiaokeyan.com/academic-journal-cn\_computer-application-abstracts\_thesis/02012160321997.html](https://m.zhangqiaokeyan.com/academic-journal-cn_computer-application-abstracts_thesis/02012160321997.html)

\[33] LEAP: LLM-powered End-to-end Automatic Library for Processing Social Science Queries on Unstructured Data[ https://arxiv.org/pdf/2501.03892](https://arxiv.org/pdf/2501.03892)

\[34] Querying Databases with Function Calling[ https://arxiv.org/pdf/2502.00032](https://arxiv.org/pdf/2502.00032)

\[35] Dynamic Fog Computing for Enhanced LLM Execution in Medical Applications[ https://arxiv.org/pdf/2408.04680](https://arxiv.org/pdf/2408.04680)